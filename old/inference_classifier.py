"""
åˆ†é¡æ¨ç†è…³æœ¬
Scientific Image Forgery Detection

ç”Ÿæˆæäº¤æª”æ¡ˆ (case_id, annotation)

ä½¿ç”¨æ–¹æ³•:
    python inference_classifier.py --checkpoint outputs/best_classifier.pth
    python inference_classifier.py --checkpoint outputs/best_classifier.pth --tta
"""

import os
import argparse
from pathlib import Path
from tqdm import tqdm
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from PIL import Image
import cv2
import timm

from dataset_classification import (
    ForgeryTestDataset, 
    get_val_transforms, 
    get_tta_transforms
)
from train_classifier import ForgeryClassifier
from utils import get_device


def parse_args():
    parser = argparse.ArgumentParser(description='Inference for Forgery Classification')
    
    parser.add_argument('--checkpoint', type=str, required=True)
    parser.add_argument('--data_dir', type=str, default='./data')
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument('--submission_name', type=str, default='submission.csv')
    
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--image_size', type=int, default=384)
    parser.add_argument('--threshold', type=float, default=0.5,
                       help='Threshold for forged prediction')
    parser.add_argument('--tta', action='store_true',
                       help='Use Test Time Augmentation')
    
    return parser.parse_args()


def load_model(checkpoint_path, device):
    """è¼‰å…¥æ¨¡å‹"""
    checkpoint = torch.load(checkpoint_path, map_location=device)
    args = checkpoint.get('args', {})
    
    model_name = args.get('model', 'efficientnet_b0')
    dropout = args.get('dropout', 0.3)
    
    print(f"Loading {model_name}...")
    
    model = ForgeryClassifier(
        model_name=model_name,
        num_classes=2,
        pretrained=False,
        dropout=dropout
    )
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    best_score = checkpoint.get('best_score', 0)
    print(f"Model loaded. Best validation F1: {best_score:.4f}")
    
    return model, args


def predict_batch(model, images, device):
    """æ‰¹æ¬¡é æ¸¬"""
    with torch.no_grad():
        outputs = model(images.to(device))
        probs = F.softmax(outputs, dim=1)
    return probs.cpu().numpy()


def predict_with_tta(model, image_np, tta_transforms, device):
    """TTA é æ¸¬"""
    probs_list = []
    
    for transform in tta_transforms:
        augmented = transform(image=image_np)
        img_tensor = augmented['image'].unsqueeze(0).to(device)
        
        with torch.no_grad():
            outputs = model(img_tensor)
            probs = F.softmax(outputs, dim=1)
        
        probs_list.append(probs.cpu().numpy())
    
    # å¹³å‡
    avg_probs = np.mean(probs_list, axis=0)
    return avg_probs


def main():
    args = parse_args()
    
    device = get_device()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥æ¨¡å‹
    print("\nğŸ”§ Loading model...")
    model, model_args = load_model(args.checkpoint, device)
    
    # è³‡æ–™è·¯å¾‘
    data_dir = Path(args.data_dir)
    test_dir = data_dir / 'test_images'
    sample_sub_path = data_dir / 'sample_submission.csv'
    
    # è®€å– sample submission äº†è§£æ ¼å¼
    if sample_sub_path.exists():
        sample_df = pd.read_csv(sample_sub_path)
        print(f"\nSample submission format:")
        print(sample_df.head())
        id_col = sample_df.columns[0]  # case_id
        annotation_col = sample_df.columns[1]  # annotation
    else:
        id_col = 'case_id'
        annotation_col = 'annotation'
    
    # æº–å‚™è½‰æ›
    image_size = (args.image_size, args.image_size)
    transform = get_val_transforms(image_size)
    tta_transforms = get_tta_transforms(image_size) if args.tta else None
    
    # æ”¶é›†æ¸¬è©¦åœ–åƒ
    print(f"\nğŸ“Š Collecting test images from {test_dir}...")
    
    test_images = []
    
    # æª¢æŸ¥æ¸¬è©¦ç›®éŒ„çµæ§‹
    if test_dir.exists():
        # å¯èƒ½æœ‰å­ç›®éŒ„
        for item in test_dir.iterdir():
            if item.is_dir():
                for f in item.iterdir():
                    if f.suffix.lower() in ['.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp']:
                        test_images.append(f)
            elif item.suffix.lower() in ['.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp']:
                test_images.append(item)
    
    test_images = sorted(test_images)
    print(f"Found {len(test_images)} test images")
    
    if len(test_images) == 0:
        print("âŒ No test images found!")
        return
    
    # æ¨ç†
    print(f"\nğŸš€ Running inference {'with TTA' if args.tta else ''}...")
    
    results = []
    
    for img_path in tqdm(test_images, desc='Inference'):
        # è®€å–åœ–åƒ
        image = cv2.imread(str(img_path))
        if image is None:
            image = np.array(Image.open(img_path).convert('RGB'))
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # é æ¸¬
        if args.tta:
            probs = predict_with_tta(model, image, tta_transforms, device)
        else:
            augmented = transform(image=image)
            img_tensor = augmented['image'].unsqueeze(0).to(device)
            
            with torch.no_grad():
                outputs = model(img_tensor)
                probs = F.softmax(outputs, dim=1).cpu().numpy()
        
        # ç²å–é æ¸¬
        prob_forged = probs[0, 1]  # P(forged)
        prediction = 'forged' if prob_forged > args.threshold else 'authentic'
        
        # æå– case_id (é€šå¸¸æ˜¯æ–‡ä»¶åçš„æ•¸å­—éƒ¨åˆ†)
        case_id = img_path.stem
        # å˜—è©¦æå–æ•¸å­— ID
        try:
            case_id = int(''.join(filter(str.isdigit, case_id)))
        except:
            pass
        
        results.append({
            id_col: case_id,
            annotation_col: prediction,
            'prob_forged': prob_forged  # ä¿å­˜æ¦‚ç‡ä¾›åˆ†æ
        })
    
    # å‰µå»ºæäº¤ DataFrame
    submission_df = pd.DataFrame(results)
    
    # ä¿å­˜å®Œæ•´çµæœ (åŒ…å«æ¦‚ç‡)
    full_results_path = output_dir / 'predictions_with_probs.csv'
    submission_df.to_csv(full_results_path, index=False)
    print(f"\nğŸ“Š Full predictions saved to: {full_results_path}")
    
    # å‰µå»ºæäº¤æª”æ¡ˆ (åªæœ‰ case_id å’Œ annotation)
    submission_df = submission_df[[id_col, annotation_col]]
    submission_path = output_dir / args.submission_name
    submission_df.to_csv(submission_path, index=False)
    
    print(f"âœ… Submission saved to: {submission_path}")
    print(f"   Total predictions: {len(submission_df)}")
    
    # çµ±è¨ˆ
    n_authentic = (submission_df[annotation_col] == 'authentic').sum()
    n_forged = (submission_df[annotation_col] == 'forged').sum()
    print(f"\nğŸ“ˆ Prediction statistics:")
    print(f"   Authentic: {n_authentic} ({n_authentic/len(submission_df)*100:.1f}%)")
    print(f"   Forged: {n_forged} ({n_forged/len(submission_df)*100:.1f}%)")
    
    # é¡¯ç¤ºå‰å¹¾å€‹çµæœ
    print("\nFirst 10 predictions:")
    print(submission_df.head(10))
    
    # ç¹ªè£½æ¦‚ç‡åˆ†ä½ˆ
    import matplotlib.pyplot as plt
    
    full_df = pd.read_csv(full_results_path)
    
    plt.figure(figsize=(10, 4))
    
    plt.subplot(1, 2, 1)
    plt.hist(full_df['prob_forged'], bins=50, edgecolor='black', alpha=0.7)
    plt.axvline(x=args.threshold, color='r', linestyle='--', label=f'Threshold={args.threshold}')
    plt.xlabel('P(Forged)')
    plt.ylabel('Count')
    plt.title('Distribution of Forged Probabilities')
    plt.legend()
    
    plt.subplot(1, 2, 2)
    plt.pie([n_authentic, n_forged], 
           labels=['Authentic', 'Forged'],
           autopct='%1.1f%%',
           colors=['lightgreen', 'salmon'])
    plt.title('Prediction Distribution')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'prediction_distribution.png', dpi=150)
    plt.close()
    
    print(f"\nğŸ“Š Distribution plot saved to: {output_dir / 'prediction_distribution.png'}")


if __name__ == '__main__':
    main()
